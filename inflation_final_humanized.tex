% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,letterpaper]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage[]{mathptmx}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{caption}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3} % enable section numbering
\usepackage{booktabs}\usepackage{needspace}\usepackage{float}\usepackage{natbib}\usepackage{url}\usepackage{graphicx}\usepackage{hyperref}\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}
\setcounter{table}{0}
\setcounter{figure}{0}

\title{Measuring What Matters: A Comparative Analysis of Official and Alternative Inflation Metrics with Novel Distributional Approaches}
\author{Working Paper}
\date{December 2025}

\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{abstract}
U.S. inflation measurement has evolved to report lower numbers, and the
impact falls hardest on those least able to verify it. This paper shows
that machine intelligence now lets anyone check the math.

We synthesize existing research comparing official government
methodology, alternative private measures, and novel analytical
approaches. The findings: (1) cumulative methodological changes to the
Consumer Price Index since 1980 have lowered measured inflation by
approximately 5.1 percentage points over 31 years (per BLS's own
CPI-U-RS series); (2) real-time alternative measures diverge from
official CPI by 1-2 percentage points during volatile periods; (3)
inflation inequality across income and racial groups is large: the
lowest income quintile experiences 10\% higher cumulative inflation than
the highest, and Black and Hispanic households face 0.4-0.6 percentage
point higher annual inflation than white households. These findings are
well-documented in Federal Reserve research but absent from popular
discourse.

We construct five novel metrics from publicly available data:
necessities have inflated 35 percentage points more than discretionary
goods since 2000; asset-adjusted inflation exceeds official CPI by 29\%;
labor-hours required for a home down payment have increased 84\% since
1990; protein costs require 35-42\% more work-minutes to purchase than
in 1990. The Argentina case study (2007-2015) illustrates how
independent measurement can expose official manipulation.

This paper situates inflation measurement within a broader framework of
epistemic authority. Drawing on Stiglitz, Foucault, and Scott, we argue
that machine intelligence disrupts traditional monopolies on economic
measurement. The analyses here synthesize work across economics,
sociology, and political philosophy, fields whose practitioners rarely
read each other. Machine intelligence enables polymath capability:
fluency across disciplinary languages in a world where specialization
makes such breadth rare. This capacity, now widely accessible, portends
a transformation in who can produce authoritative knowledge about
economic conditions.
\end{abstract}

\bigskip
\noindent \textit{Keywords}: inflation measurement; CPI methodology; distributional effects; alternative data; price indices; information asymmetry; epistemic authority; machine intelligence

\noindent \textit{JEL classification}: E31, E01, D31, C43, D83
\bigskip

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Introduction}\label{sec:introduction}

The accurate measurement of price changes is foundational to economic
policy, contract indexation, and household financial planning. In the
United States, the Bureau of Labor Statistics (BLS) Consumer Price Index
(CPI) serves as the primary official measure, influencing Social
Security adjustments, tax brackets, Treasury Inflation-Protected
Securities, and Federal Reserve monetary policy.

But the methodology underlying CPI calculation has undergone substantial
revision since 1980. The BLS has defended each change on technical
grounds, but the cumulative effect is directional: every major change
has lowered measured inflation. Simultaneously, advances in data
collection technology have enabled alternative private measures that
update daily rather than monthly and draw from millions rather than tens
of thousands of price observations.

And this paper contributes to the literature in four ways. First, we
synthesize the methodological evolution of official inflation
measurement and quantify its cumulative impact. Second, we
systematically compare official and alternative measures, drawing
lessons from the Argentine case where independent measurement exposed
official data manipulation. Third, we identify gaps in current
measurement and propose novel metrics that could be constructed from
publicly available data sources. Fourth, we argue that this analysis
itself exemplifies a broader transformation: the democratization of
economic measurement through machine intelligence.

Francis Bacon observed that knowledge is power. Akerlof, Spence, and
Stiglitz received the Nobel Prize for demonstrating how information
asymmetries create market failures and enable rent extraction. Foucault
showed how knowledge production is inseparable from power relations.
Scott documented how states use measurement to render populations
``legible'' and controllable. These insights converge on a single
recognition: \emph{the capacity to measure economic reality is itself a
form of power}, and that power has historically been concentrated in
institutions with resources to collect data, employ statisticians, and
disseminate findings through credentialed channels.

Machine intelligence disrupts this arrangement. A human author posed
questions; an AI system synthesized literature across disciplines that
specialists rarely have time to integrate, generated figures, and
drafted text. The result is work that would traditionally require a team
spanning economics, sociology, political science, and data science, or a
rare polymath with decades to accumulate cross-disciplinary expertise.
Readers may judge the quality for themselves. If it passes muster, the
implications for who can produce economic analysis matter.

This isn't merely a change in efficiency. it's a change in \emph{who can
know}, and therefore in who can challenge official narratives about
economic conditions. When a graduate student, a journalist, or a citizen
can produce analyses of comparable sophistication to government
statistical agencies, the information asymmetry that sustains capture
begins to erode.

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews
related literature, including work on information asymmetry and
epistemic authority. Section~\ref{sec:official} details official CPI methodology and its
evolution. Section~\ref{sec:alternatives} examines alternative measures. Section~\ref{sec:distributional} presents
distributional analysis. Section~\ref{sec:novel} proposes novel metrics. Section~\ref{sec:argentina}
presents the Argentina case study. Section~\ref{sec:machine} discusses the implications
of machine intelligence for economic measurement. Section~\ref{sec:conclusion} concludes.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Related Work}\label{sec:related}

\subsection{CPI Methodology and
Bias}\label{sec:cpi-methodology-and-}

The seminal contribution to CPI methodology critique is the Boskin
Commission Report (\citet{boskin1996toward}), which estimated that the CPI
overstated inflation by 1.1 percentage points annually due to
substitution bias, quality change bias, and new goods bias. The
Commission's recommendations led to significant methodological changes
including the geometric mean formula \citep{moulton1996bias} and enhanced
hedonic quality adjustment \citep{pakes2003reconsideration}.

Subsequent research has debated whether post-Boskin changes have
introduced downward bias. \citet{hausman2003sources} argued that hedonic adjustments
systematically underestimate quality-adjusted prices in categories with
rapid innovation. \citet{gordon2006boskin} provided a comprehensive review of
measurement issues, concluding that remaining bias is considerably
reduced but not eliminated.

The treatment of owner-occupied housing has received particular
scrutiny. \citet{diewert2003hedonic} analyzed the theoretical foundations of owner's
equivalent rent (OER), while \citet{verbrugge2008oer} documented the lag between
OER and market-based rent measures. \citet{ambrose2015repeat}
found that OER notably understates housing cost volatility during
boom-bust cycles.

\subsection{Alternative Inflation
Measures}\label{sec:alt-measures-lit}

The Billion Prices Project (BPP), initiated by Cavallo and Rigobon
(2010), pioneered the use of online price data for inflation
measurement. \citet{cavallo2013online} demonstrated that online prices could
effectively replicate official CPI behavior while providing daily rather
than monthly updates. The methodology was subsequently applied to expose
Argentine official statistics manipulation \citep{cavallo2013online}.

More recently, blockchain-based measurement systems have emerged.
Truflation (launched 2021) aggregates data from over 30 sources
including major retailers, providing daily updates verified through
decentralized consensus mechanisms (\citet{truflation2024methodology}). The system claims
significant lead time over official releases and high correlation with
headline CPI during stable periods, though independent academic
validation of these claims remains limited.

\subsection{Distributional Effects of
Inflation}\label{sec:distributional-effec}

Research on inflation inequality has accelerated in recent years. \citet{hobijn2005inflation} first documented systematic differences in inflation
rates across demographic groups using Consumer Expenditure Survey data.
\citet{jaravel2019unequal} extended this analysis to show that product innovation
disproportionately benefits higher-income consumers, creating a form of
unmeasured inflation inequality.

\citet{argente2021cost} examined inflation during the COVID-19 pandemic,
finding wide variation across income groups driven by differential
consumption baskets. The Federal Reserve Banks of Minneapolis \citep{heise2024lower}, New York \citep{armantier2023inflation}, and Richmond \citep{kudlyak2022black} have all published research documenting persistent
inflation gaps by race and income.

This inflation inequality research builds on a deeper tradition of
scholarship on racial economic disparities. \citet{darity1998persistent}
established foundational analysis of persistent racial wealth gaps;
\citet{darity2012bold} documented how these gaps compound across
generations. \citet{oliver2006black} showed that racial wealth
inequality dwarfs income inequality, with implications for how inflation
affects different communities' capacity to build assets. More recently,
Derenoncourt et al.~(2022) traced the historical evolution of the
Black-white wealth gap, finding that convergence stalled after 1980,
precisely when CPI methodology changes documented in Section~\ref{sec:official} began
accumulating. We don't claim causation, but the temporal coincidence
merits attention: the period of stalled racial wealth convergence
overlaps with the period of cumulative downward methodology adjustments
to the index that determines real wage growth, Social Security
adjustments, and inflation-indexed benefits.

\subsection{Information Asymmetry and Epistemic
Authority}\label{sec:information-asymmetr}

The economics of information, pioneered by \citet{akerlof1970lemons}, Spence
(1973), and \citet{stiglitz1975screening}, establishes that unequal access to
information creates systematic market failures. Their Nobel
Prize-winning work demonstrated that information asymmetries enable
adverse selection, moral hazard, and rent extraction by better-informed
parties. As \citet{stiglitz2017revolution} noted in his retrospective, ``new technology
has increased the ability to exploit information asymmetries and enhance
the market power of those who have differential information.''

This insight extends beyond product markets to knowledge production
itself. \citet{foucault1975discipline,foucault1980power} argued that knowledge and power are
inseparable: ``knowledge is a form of power and can conversely be used
against individuals as a form of power.'' Knowledge, in this view, is
socially constructed through discourses that reflect and reinforce
dominant interests. The question isn't simply ``What is true?'' but
``Who has the authority to declare what is true, and whose interests
does that authority serve?''

Bourdieu (1975, 2004) developed this analysis specifically for
scientific knowledge, demonstrating that access to various forms of
capital influences the production, validation, and dissemination of
knowledge. The scientific field isn't a neutral space of inquiry but a
site of competition where power dynamics shape what questions are asked,
what methods are legitimate, and whose findings achieve authority.

\citet{scott1998seeing} provided perhaps the most direct analysis of measurement as
power in \emph{Seeing Like a State}. He documented how states use
statistical measurement to render populations ``legible,'' simplifying
complex social realities into categories amenable to control. ``The
premodern state was, in many crucial respects, partially blind,'' Scott
observed. ``It knew precious little about its subjects, their wealth,
their landholdings and yields, their location, their very identity.''
The development of censuses, standardized weights and measures, and
economic statistics wasn't merely technical progress but an expansion of
state capacity to monitor and intervene.

Stigler's (1971) theory of regulatory capture completes this framework.
Regulated industries, with concentrated stakes in regulatory outcomes,
systematically influence the regulators tasked with overseeing them.
Information asymmetry is central to this process: regulators depend on
industry for operational knowledge, creating structural vulnerability to
capture. \citet{gilens2014testing} extended this analysis, finding that
``economic elites and organized interests'' have disproportionate
influence over policy outcomes relative to the general public.

These literatures converge on a recognition that official economic
statistics aren't neutral technical products but emerge from
institutional contexts shaped by power relations, resource constraints,
and potential capture. Independent verification by parties not subject
to the same structural pressures is therefore valuable. Not because
official statistics are wrong, but because the possibility of bias
warrants scrutiny regardless of whether bias exists.

\textbf{The case for official statistics.} Fairness requires
acknowledging the strong arguments in favor of official methodology. The
BLS has strong institutional incentives for accuracy: bond markets,
Federal Reserve policy, and Social Security trust fund projections all
depend on CPI reliability, creating powerful constituencies for
measurement integrity. The methodology changes documented in Section~\ref{sec:official}
were responses to legitimate technical critiques: the Boskin Commission
identified real biases (substitution, quality change, new goods) that
overstated inflation. Academic peer review of BLS methodology is
extensive, and alternative measures have repeatedly been shown to
contain their own biases. The credentialing requirements that limit
access to statistical production also serve quality-control functions.
ShadowStats (Section~4.3) shows what happens when methodological rigor
is absent. We don't assume capture; we argue only that the
\emph{possibility} of capture warrants independent verification, not
that capture has occurred.

\subsection{Nature of This Study's
Contribution}\label{sec:nature-of-this-study}

To avoid overstating novelty, we distinguish three categories of
contribution:

\textbf{Restatement of established facts.} Much of what we present isn't
new. The cumulative effect of CPI methodology changes is documented in
the BLS's own CPI-U-RS research series. Inflation inequality by income
and race has been established by Federal Reserve researchers at
Minneapolis, New York, and Richmond. The Argentina manipulation case is
definitively documented in \citet{cavallo2013online}. We restate these findings to
make them accessible to non-specialist audiences; the findings
themselves aren't our contribution.

\textbf{Novel synthesis.} The integration of technical inflation
measurement with epistemological frameworks (Foucault, Bourdieu, Scott,
Stigler) represents synthesis across literatures that don't typically
communicate. Economic statisticians rarely cite critical theory; STS
scholars rarely engage with CPI methodology details. Whether this
synthesis illuminates or merely juxtaposes is for readers to judge, but
the combination isn't present in prior work we've identified.

\textbf{Original contributions.} We claim originality for: (1) the
specific operationalization and construction of five novel metrics
(time-cost index, necessity/discretionary split, asset-adjusted CPI,
first-time buyer affordability, grocery basket time-cost) with
historical data; (2) the framing of machine intelligence as enabling
epistemic democratization specifically in economic measurement; and (3)
this paper itself as a demonstration artifact of AI-assisted research
capabilities.

We don't claim to have discovered inflation inequality, identified CPI
methodology changes, or invented the concept of alternative price
measurement. These are established facts and methods. Our contribution
is synthesis, accessibility, and the novel metrics constructed in
Section~\ref{sec:novel}.

\subsection{AI-Assisted Research: Prior Work and This Paper's
Place}\label{sec:ai-assisted-research}

The use of AI systems for research assistance is not novel. Early work
on automated literature review \citep{marshall2019systematic} demonstrated
that machine learning could accelerate systematic reviews in medicine.
More recently, large language models have been applied to scientific
synthesis \citep{taylor2022galactica}, code generation for data analysis \citep{chen2021evaluating}, and automated report generation in financial services
\citep{lopezlira2023chatgpt}.

What distinguishes this paper is not the use of AI assistance (that's
increasingly common) but the explicit framing of AI-assisted research as
a democratizing force in a domain (economic measurement) where epistemic
authority has historically been concentrated. Prior work on AI in
economics has focused on prediction \citep{mullainathan2017machine},
policy evaluation \citep{athey2019machine}, and market analysis. We
extend this to the meta-level: not merely using AI to do economics, but
arguing that AI changes \emph{who can do} economics.

This framing has precedents. \citet{benkler2006wealth} argued that networked
information technology enables ``commons-based peer production'' that
challenges proprietary knowledge production. \citet{shirky2008here} documented
how reduced coordination costs enable collective action previously
impossible. We situate AI-assisted analysis as the latest instance of
this pattern, with the caveat that technological capability doesn't
guarantee democratization of authority (see Section~8.6).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Official Inflation
Methodology}\label{sec:official}

Understanding how official inflation is measured is essential to
evaluating claims about its accuracy. This section documents CPI
construction methodology and the cumulative effect of changes since
1980. The key finding: every major methodology change has lowered
measured inflation, with cumulative impact of approximately 5.1
percentage points over 31 years according to the BLS's own research
series. Whether these changes represent genuine measurement improvement
or introduce systematic downward bias is the central question this paper
invites readers to consider.

\subsection{Consumer Price Index
Construction}\label{sec:consumer-price-index}

The BLS constructs the CPI by tracking prices of approximately 80,000
items monthly across urban areas, representing a ``market basket'' of
consumer goods and services (\citet{bls2024concepts}). Prices are collected from
retail establishments, service providers, and housing units selected
through probability sampling.

The CPI-U (all urban consumers) covers approximately 93\% of the U.S.
population. The CPI-W (urban wage earners and clerical workers) covers a
subset used primarily for Social Security cost-of-living adjustments.

\subsection{Key Methodological
Components}\label{sec:key-methodological-c}

\textbf{Hedonic Quality Adjustment}: When product characteristics change
alongside prices, the BLS decomposes items into constituent features and
estimates the value of each through regression modeling (\citet{bls2024quality}).
The quality-adjusted price change removes value attributable to
characteristic improvements. Early BLS research suggested hedonic
adjustments had minimal net effect on aggregate CPI (Moulton \& Moses,
1997), though the impact varies by category, with technology products
showing larger adjustments than other goods.

\textbf{Geometric Mean Formula}: Adopted in January 1999, the geometric
mean formula allows for consumer substitution within item categories
(\citet{bls1999geometric}). This replaced the arithmetic mean, which assumed fixed
consumption quantities regardless of relative price changes. The change
lowered measured inflation by approximately 0.28 percentage points
annually.

\textbf{Owner's Equivalent Rent}: Since 1987, housing costs for
owner-occupied units are measured not by transaction prices or mortgage
payments but by asking owners what their home could rent for (BLS,
2024c). This approach treats homeownership as a service consumption
decision rather than an investment. Housing comprises approximately 33\%
of CPI weight.

\textbf{Chained CPI-U}: Introduced in August 2002, the chained CPI uses
expenditure data from both current and prior periods, allowing
consumption basket changes in response to price movements (\citet{bls2002chained}).
This yields inflation approximately 0.25 percentage points lower than
traditional CPI.

\subsection{Cumulative Effect of Methodology
Changes}\label{sec:cumulative-effect-of}

Table~\ref{tab:methodology-changes} summarizes major methodology changes and their estimated
effects.

\needspace{3in}
\begin{longtable}[]{@{}
lll@{}}
\toprule\noalign{}
Year & Change & Estimated Annual Effect \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1983 & OER replaces direct housing costs & Indeterminate \\
1999 & Geometric mean formula & -0.28 pp \\
2002 & Chained CPI introduced & -0.25 pp \\
2018 & Smartphone hedonic adjustment & Minor \\
2023 & OER structure-type weighting & Minor \\
\caption{CPI Methodology Changes Since 1980}
\label{tab:methodology-changes}
\end{longtable}


\emph{Note: The BLS CPI-U-RS (research series) shows that applying
current methodology retroactively to 1980 data yields 5.1\% lower
cumulative prices over 31 years compared to original methodology.}

\subsection{Personal Consumption Expenditures
(PCE)}\label{sec:personal-consumption}

The Federal Reserve's preferred inflation measure since 2000 is the PCE
price index, produced by the Bureau of Economic Analysis (\citet{fomc2012statement}).
Key differences from CPI include:

\begin{itemize}
\tightlist
\item
  \textbf{Formula}: Fisher index (geometric mean of Laspeyres and
  Paasche) vs.~modified Laspeyres
\item
  \textbf{Scope}: Includes rural consumers and third-party payments
  (employer health insurance, Medicare)
\item
  \textbf{Weights}: Housing 15\% (vs.~33\% in CPI); healthcare higher
\item
  \textbf{Historical gap}: PCE typically 0.3-0.4 percentage points lower
  than CPI
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Alternative Inflation Measures}\label{sec:alternatives}

\subsection{Truflation}\label{sec:truflation}

Truflation, launched in December 2021, provides daily inflation updates
using blockchain-verified data aggregation (\citet{truflation2024methodology}). According
to the project's documentation, the methodology aggregates approximately
30 million price points from 80+ providers including Amazon, Walmart,
Zillow, and NielsenIQ, with daily updates verified through Byzantine
Fault Tolerant blockchain consensus. Truflation claims lead time over
official releases, though independent academic validation remains
limited. Unlike the Billion Prices Project, Truflation has not yet been
subject to peer-reviewed evaluation.

Current readings (as of late 2025) show Truflation at approximately
1.3-1.5\%, compared to official CPI at 2.7\%, a divergence of
approximately 1.3 percentage points. Whether this divergence reflects
methodological differences, timing effects, or genuine measurement gaps
can't be determined without more detailed analysis of Truflation's
proprietary methodology.

\textbf{Temporal caveat}: The Truflation-CPI divergence patterns
observed during the 2022-2025 post-pandemic inflationary period may not
persist in more stable economic conditions. During the 2022 inflation
peak, Truflation \emph{exceeded} official CPI; the current pattern of
CPI exceeding Truflation may reflect the particular dynamics of
disinflation rather than a permanent measurement bias. Readers should be
cautious about extrapolating current divergences into claims about
structural differences between the measures.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig3_truflation_vs_cpi.png}
\caption{Comparison of Truflation and official CPI, 2021-2025. During the 2022 peak, Truflation exceeded CPI; currently, CPI exceeds Truflation. Data: Illustrative reconstruction from publicly reported Truflation readings and BLS CPI-U releases. Note: Truflation time series reconstructed from periodic reports; not drawn from continuous API access. Precise values should be verified against primary sources.}
\label{fig:truflation}
\end{figure}


\subsection{Billion Prices Project /
PriceStats}\label{sec:billion-prices-proje}

The Billion Prices Project (BPP) was created at MIT in 2008 by Alberto
Cavallo and Roberto Rigobon to experiment with online price data for
inflation measurement \citep{cavallo2016billion}. By 2010, the project
collected 5 million prices daily from over 300 retailers in 50
countries.

The methodology applied Fisher indices with official expenditure weights
to online prices, producing indices that closely tracked official CPI in
countries with credible statistics while diverging sharply in countries
with data quality concerns \citep{cavallo2013online}.

PriceStats, the commercial spinoff, is now part of State Street's Data
Intelligence unit and continues to provide real-time inflation
indicators for institutional clients.

\subsection{ShadowStats: A Cautionary
Example}\label{sec:shadowstats-a-cautio}

John Williams' ShadowStats claims to calculate inflation using pre-1980
methodology, reporting figures 6-8 percentage points higher than
official CPI \citep{williams2024shadowstats}. However, methodological review reveals
significant problems:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ShadowStats doesn't actually recalculate using earlier methodology; it
  adds a constant adjustment to official figures \citep{hamilton2008measuring}
\item
  Cumulative claims imply 600\%+ price increases since 2000,
  contradicted by physical output data
\item
  The \$175 annual subscription price has remained unchanged since 2006
  despite claimed hyperinflation
\end{enumerate}

Academic consensus holds that ShadowStats adjustments are ``implausibly
high'' and fail cross-validation \citep{dolan2014shadowstats}. This case illustrates
that not all alternatives to official measures are methodologically
sound.

\textbf{Why ShadowStats fails and why this analysis differs.}
ShadowStats fails for three reasons this paper attempts to avoid: (1)
\emph{opaque methodology}, claiming to use ``pre-1980'' methods but
actually applying a constant adjustment without explaining its
derivation; (2) \emph{unfalsifiable claims}, with the adjustment not
tied to verifiable data that would allow independent replication; (3)
\emph{internal inconsistency}, where the operator's own pricing behavior
contradicts his inflation claims. This paper, by contrast, documents its
sources, uses publicly available data, constructs metrics that can be
independently verified, and explicitly acknowledges what it does and
doesn't claim. Whether this succeeds where ShadowStats fails is for
readers to judge, but the attempt at transparent methodology is the
relevant difference.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Distributional Analysis}\label{sec:distributional}

\subsection{Inflation by Income
Quintile}\label{sec:inflation-by-income-}

Research from the Minneapolis Fed and BLS documents persistent inflation
inequality across income groups \citep{heise2024lower,bls2024income}.

\needspace{3in}
\begin{longtable}[]{@{}
lll@{}}
\toprule\noalign{}
Income Quintile & Cumulative Inflation & Gap vs.~Average \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Lowest 20\% & 64\% & +10\% faster \\
Second 20\% & 62\% & +8\% faster \\
Middle 20\% & 60\% & Average \\
Fourth 20\% & 58\% & -2\% slower \\
Highest 20\% & 57\% & -7\% slower \\
\caption{Cumulative Inflation by Income Quintile (2005-2023)}
\label{tab:income-quintile}
\end{longtable}


The mechanism is compositional: lower-income households spend
proportionally more on necessities (housing, food, energy) with higher
price volatility and fewer substitution options.

\subsection{Inflation by Race and
Ethnicity}\label{sec:inflation-by-race-an}

Federal Reserve research documents significant inflation disparities by
race \citep{armantier2022inflation,kudlyak2022black}.

\needspace{3in}
\begin{longtable}[]{@{}
ll@{}}
\toprule\noalign{}
Group & Peak Gap vs.~National Average \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hispanic & +1.5 pp (June 2021) \\
Black & +1.0 pp (February 2022) \\
White & Baseline \\
AAPI & -0.3 pp \\
\caption{Peak Inflation Gap by Race/Ethnicity (2021-2022)}
\label{tab:race-gap}
\end{longtable}


These gaps are driven by spending composition differences: Hispanic
households spend larger shares on transportation (particularly used
vehicles and fuel); Black households allocate more to housing with lower
homeownership rates.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig4_race_inflation_disparity.png}
\caption{Inflation disparities by race/ethnicity during 2021-2022. Data: Peak gaps derived from \citet{armantier2022inflation} and \citet{kudlyak2022black}. Financial stress data from Harvard/Robert Wood Johnson Foundation poll. Note: Figure is illustrative; precise gap magnitudes vary by time period and methodology.}
\label{fig:race-disparity}
\end{figure}


\subsection{Geographic Variation}\label{sec:geographic-variation}

Regional CPI data shows meaningful variation even within the United
States (\citet{bls2025summary}).

\needspace{3in}
\begin{longtable}[]{@{}
ll@{}}
\toprule\noalign{}
Region & 12-Month CPI \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
National Average & 2.7\% \\
Midwest & 3.0\% \\
Northeast & 3.1\% \\
NY-Newark-Jersey City & 3.0\% (energy +8.4\%) \\
\caption{Regional CPI Variation (November 2025)}
\label{tab:regional-cpi}
\end{longtable}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig5_regional_variation.png}
\caption{Regional CPI variation, November 2025. Data: BLS regional CPI releases. Values reflect official BLS data.}
\label{fig:regional}
\end{figure}


\subsection{Spending Composition
Differences}\label{sec:spending-composition}

Figure~\ref{fig:spending-composition} illustrates how spending composition varies across income
levels, explaining differential inflation exposure.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig6_spending_composition.png}
\caption{Spending composition by income quintile. Lower-income households allocate larger shares to necessities with higher and more volatile price growth. Data: BLS Consumer Expenditure Survey. Note: Percentages are representative values; precise shares vary by year and survey methodology.}
\label{fig:spending-composition}
\end{figure}


The following section shows how these aggregate patterns manifest in
individual experience.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Novel Metrics: A
Demonstration}\label{sec:novel}

\subsection{Maria's Question}\label{sec:marias-question}

Consider Maria, a nursing assistant in Cleveland earning \$17 per hour,
close to the BLS median for nursing assistants in Ohio. Her household
income places her in the second quintile documented in Section~5.1. In
2024, she reads that inflation has fallen to 2.7\%, nearly back to the
Fed's target. But her grocery bills tell a different story. Eggs cost
twice what they did three years ago. Ground beef has become a luxury.
Her rent increased 12\% last year. She wonders: is the official number
wrong, or is something else going on?

Maria's intuition is correct, but the explanation is subtle. CPI
measures the average urban consumer's experience. Maria is not average.
She is in the second quintile experiencing the 10\%+ cumulative
inflation gap documented in Section~\ref{sec:distributional}. She spends more of her income on
food and rent than wealthier households do. She doesn't benefit from
falling prices on electronics and apparel. The aggregate statistic is
accurate for what it measures, but what it measures may not be her life.

With access to the same public data the BLS uses, what could Maria
discover about her own inflation experience? This section shows five
metrics she could construct, requiring no proprietary data, no
institutional resources, and no specialized training beyond what AI
assistance now provides.

\subsection{How Many Minutes to Buy
Groceries?}\label{sec:how-many-minutes-to-}

Maria's first question is visceral: how much longer does she have to
work to buy the same groceries?

\needspace{3in}
\begin{longtable}[]{@{}
llll@{}}
\toprule\noalign{}
Good & 1990 & 2024 & Change \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Gallon of Milk & 12.9 min & 10.3 min & -20\% \\
Dozen Eggs & 6.1 min & 8.2 min & +35\% \\
Pound of Ground Beef & 9.8 min & 13.9 min & +42\% \\
Gallon of Gasoline & 7.0 min & 8.4 min & +21\% \\
\caption{Time-Cost Index (Minutes of Work to Purchase)}
\label{tab:time-cost}
\end{longtable}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_time_cost_index.png}
\caption{Time-cost index showing work-minutes required to purchase common items, 1990-2024. Data from BLS median hourly wages and average price data.}
\label{fig:time-cost}
\end{figure}


Maria discovers that milk has gotten cheaper in work-time terms (20\%
less labor to buy a gallon than in 1990). But the proteins her family
relies on have gotten dramatically more expensive: eggs require 35\%
more work time, ground beef 42\% more. Avian flu, environmental
constraints on cattle production, the land-intensity of protein: these
factors are invisible in aggregate CPI, which averages everything
together. Maria's grocery basket hasn't experienced 2.7\% inflation. Her
basket has inflated faster than her wage.

\subsection{Why Do Necessities Cost
More?}\label{sec:why-do-necessities-c}

Maria's second question: what about everything she \emph{has} to buy
versus things she could skip? She separates CPI components into
necessities (food, shelter, utilities, medical care, basic
transportation) and discretionary spending (recreation, apparel,
entertainment).

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_necessity_discretionary.png}
\caption{Necessity vs.\ discretionary inflation, 2000-2024. Data from BLS CPI component indices.}
\label{fig:necessity-discretionary}
\end{figure}


The result is stark: by 2024, necessities have risen to 220 (2000=100)
while discretionary goods reached only 185, a 35 percentage point gap.
Maria spends 70\% of her income on necessities; a wealthier household
might spend 40\%. This single fact explains much of her frustration: the
things she can't avoid have inflated nearly twice as fast as the things
she can.

The policy implication is direct: Social Security COLA adjustments based
on aggregate CPI systematically undercompensate people like Maria. The
BLS has an experimental CPI-E for the elderly, but no necessity-weighted
index exists for working-age low-income households. Until someone like
Maria constructs one.

\subsection{What About the Assets She Doesn't
Own?}\label{sec:what-about-the-asset}

Maria doesn't own a home or stocks. CPI tells her that her purchasing
power, adjusted for inflation, has grown modestly since 2000. But CPI
excludes asset prices entirely, treating housing as rent, ignoring
financial assets. What if she constructed an index including the things
she's trying to save for?

\needspace{3in}
\begin{longtable}[]{@{}
llll@{}}
\toprule\noalign{}
Year & Official CPI & Asset-Adjusted & Divergence \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2000 & 100 & 100 & 0\% \\
2010 & 122 & 128 & +5\% \\
2020 & 152 & 185 & +22\% \\
2024 & 183 & 236 & +29\% \\
\caption{CPI vs.~Asset-Adjusted Index (2000 = 100)}
\label{tab:asset-adjusted}
\end{longtable}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_asset_adjusted.png}
\caption{Asset-adjusted vs.\ official CPI, 2000-2024. Data from BLS CPI-U, Case-Shiller National Home Price Index, and S\&P 500 via FRED.}
\label{fig:asset-adjusted}
\end{figure}


The gap has accelerated: 5\% in 2010, 22\% in 2020, 29\% in 2024. For
Maria, this means the goalposts are moving faster than she can run. Her
``real wage gains'' measured against CPI are illusory: the assets she's
trying to accumulate are inflating faster than her wages. The Piketty
thesis (r \textgreater{} g) in personal terms: her labor is losing
ground to capital she doesn't own.

\subsection{Can She Ever Buy a
House?}\label{sec:can-she-ever-buy-a-h}

Maria's parents bought their first home when her father was 28, working
as a machinist. They saved for a down payment in about a year. Maria is
34 and has been saving for five years. She's still not close. Is this
just her, or has something structural changed?

\needspace{3in}
\begin{longtable}[]{@{}
lll@{}}
\toprule\noalign{}
Year & Hours for 20\% Down & Years of Full-Time Work \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1990 & 1,908 hours & 0.9 years \\
2000 & 2,182 hours & 1.1 years \\
2010 & 2,609 hours & 1.3 years \\
2020 & 3,012 hours & 1.4 years \\
2024 & 3,504 hours & 1.7 years \\
\caption{First-Time Buyer Affordability}
\label{tab:housing-affordability}
\end{longtable}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_housing_affordability.png}
\caption{First-time buyer housing affordability, 1990-2024. Data from Case-Shiller National Home Price Index and BLS median hourly wage statistics via FRED.}
\label{fig:housing-affordability}
\end{figure}


It's not just her. The entry barrier to homeownership has increased 84\%
in labor terms since 1990. Her father needed 0.9 years of gross wages
for a down payment; she needs 1.7 years. CPI housing, measured through
``owner's equivalent rent,'' captures the cost of \emph{staying} in a
home, not the increasingly impossible task of \emph{entering} ownership.
This is the wealth-building barrier that declining intergenerational
mobility statistics describe. Maria can now put a number on it.

\subsection{Putting It Together}\label{sec:putting-it-together}

Maria constructs a simple grocery basket (milk, eggs, beef, bread,
gasoline) and tracks both dollar-cost and time-cost over the past two
decades.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig_grocery_basket.png}
\caption{Grocery basket time-cost index, 1990-2024. Data from BLS average price data and median hourly wage statistics.}
\label{fig:grocery-basket}
\end{figure}


The 2020-2024 period shows time-cost acceleration exceeding dollar-cost
trends. Wages have not kept pace with grocery inflation. Regardless of
what headline CPI says, the time required to feed Maria's family has
increased faster than the time required to earn the dollars.

\subsection{What Maria Learned}\label{sec:what-maria-learned}

\needspace{3in}
\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Metric & Finding \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Time-Cost & Eggs +35\%, beef +42\% in work-minutes since 1990 \\
Necessities & 35 points higher inflation than discretionary goods \\
Asset-Adjusted & 29\% higher than official CPI \\
Housing Entry & 84\% more work-hours for down payment \\
\caption{Maria's Findings Summary}
\label{tab:maria-findings}
\end{longtable}

Maria now has language for her experience. She is not imagining things.
The official statistics aren't lying; they are measuring something
different from her life. And she constructed these metrics herself,
using the same public data the government uses, with no specialized
training.

This is the point. Maria's frustration with official statistics is
shared by millions. Previously, those millions could only say ``it feels
worse.'' Now they can say ``here is the data.'' They can construct the
metrics that matter to their lives. They can challenge the framing of
official statistics not with anger but with numbers.

What does Maria do next? She shares her analysis with her union's
research director, who incorporates the necessity-weighted inflation
data into contract negotiations. She posts a simplified version to a
Facebook group for healthcare workers, where it's shared hundreds of
times. A local journalist notices and writes a story about ``hidden
inflation'' affecting working families. A city councilmember cites the
time-cost data in a hearing on living wage ordinances.

None of this is guaranteed, of course. Maria's analysis might be
ignored; the journalist might not call back; the councilmember might
rarely see it. But the capability now exists. It required only a
question, public data, and a tool that could help her find the answer.

Whether this capability will be used wisely, whether it will produce
better understanding or merely alternative tribal truths, remains to be
seen. But the capability is no longer reserved for credentialed experts.
Maria can do this. Anyone can do this.

\subsection{Data Gaps: What We can't
Measure}\label{sec:data-gaps-what-we-ca}

The preceding analyses show what is possible with available data.
Equally important is identifying what \emph{can't} currently be measured
due to data limitations.

\textbf{Individual-level inflation tracking} would allow construction of
personal inflation rates based on actual household purchases, revealing
the distribution of inflation experiences within demographic groups and
identifying ``inflation-vulnerable'' household profiles. The Consumer
Expenditure Survey provides demographic breakdowns but not continuous
individual-level purchase data; credit card transaction data exists but
is proprietary and lacks price-level detail. Given the variance we
observe across demographic groups (Section~\ref{sec:distributional}), within-group variance is
likely substantial but unmeasured.

\textbf{Real-time shrinkflation detection} would track package size
changes systematically across consumer products. No historical database
of package sizes exists; GAO and academic studies sample sporadically;
retailer data is proprietary. Given GAO findings of 3 percentage point
hidden inflation in household paper products alone, systematic
measurement would likely reveal meaningful additions to headline
inflation across multiple categories.

\textbf{Fine-resolution geographic price variation} would enable
neighborhood-level price tracking. CPI regional data covers only broad
metropolitan areas, leaving within-city variation (food deserts, price
discrimination by neighborhood demographics) invisible. Given documented
disparities in food access and pricing by neighborhood income and racial
composition, we would expect substantial variation invisible to current
measurement.

\textbf{Quality-adjusted services pricing} would track service quality
changes (wait times, staff ratios, appointment availability) alongside
prices. Hedonic adjustment exists for goods but is minimal for services.
Quality deterioration in healthcare, education, and government services
represents hidden inflation large enough to alter conclusions about real
wage growth in service-intensive consumption categories.

\textbf{Wealth-contingent pricing} would track how prices differ based
on buyer characteristics (credit scores, insurance status, negotiating
power). CPI measures posted prices, not transaction prices; price
discrimination based on buyer characteristics is extensive but
unmeasured. This data would quantify ``poverty premiums'' and help
explain within-income-group variation in inflation experience.

\textbf{Expectation-outcome gaps} would link survey-based inflation
expectations (Michigan, NY Fed) to actual purchase behavior. This would
reveal how expectation errors affect household decisions and whether
expectation biases exist by demographic group, potentially explaining
some of the political polarization around inflation perceptions noted in
Section~\ref{sec:distributional}.

\subsection{Implications for Measurement
Policy}\label{sec:implications-for-mea}

The demonstrated metrics and identified gaps suggest several directions.
BLS could produce necessity vs.~discretionary indices, time-cost
tracking, and finer geographic disaggregation with existing collection
infrastructure. Linking price data to credit card transactions, tax
records, or SNAP purchase data would enable individual-level analysis
without new collection burden. Crowdsourced smartphone apps could enable
citizen-contributed price observations addressing geographic coverage
gaps. Publication of CPI microdata and computational code would enable
independent replication and alternative weighting schemes. Experimental
indices incorporating housing and financial assets would provide
complementary perspective to consumption-only measures.

The barriers to these improvements aren't technical but institutional.
The data exists or could be collected. The analytical capability exists.
What is lacking is the institutional will to prioritize distributional
transparency over headline simplicity.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig8_novel_metrics_framework.png}
\caption{Framework for novel inflation metrics showing data sources and proposed indices.}
\label{fig:metrics-framework}
\end{figure}


\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Case Study: Argentina
(2007-2015)}\label{sec:argentina}

The Argentine experience provides the clearest example of independent
measurement exposing official statistics manipulation.

\subsection{Background}\label{sec:background}

In February 2007, the Kirchner government dismissed Graciela Bevacqua,
head of INDEC's prices department, following pressure to lower inflation
estimates \citep{cavallo2013online}. Subsequently, INDEC modified methodology to
minimize reported price pressures.

\subsection{Divergence}\label{sec:divergence}

The Billion Prices Project began tracking Argentine prices in 2008,
revealing systematic divergence:

\needspace{3in}
\begin{longtable}[]{@{}
lll@{}}
\toprule\noalign{}
Measure & Annual Rate (April 2012) & Cumulative (2007-2015) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Official INDEC & 10.6\% & \textasciitilde60\% \\
Billion Prices Project & 25\% & \textasciitilde137\% \\
\caption{Argentina Official vs.~Independent Inflation}
\label{tab:argentina}
\end{longtable}


\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{figures/fig7_argentina_case.png}
\caption{Official INDEC vs.~Billion Prices Project inflation measurement in Argentina, 2007-2015. Data: Reconstructed from \citet{cavallo2013online} and contemporary press reports. Note: Cumulative values are approximate reconstructions; figure is illustrative of the magnitude of divergence documented in academic literature. Precise values should be verified against \citet{cavallo2013online} primary data.}
\label{fig:argentina}
\end{figure}


\subsection{Consequences}\label{sec:consequences}

\begin{itemize}
\tightlist
\item
  \textbf{February 2012}: The Economist ceased publishing INDEC figures
\item
  \textbf{2013}: International Monetary Fund issued declaration of
  censure
\item
  \textbf{Poverty understatement}: Real extreme poverty 6.69\%
  vs.~official 2.5\%
\item
  \textbf{Bondholder losses}: Inflation-linked securities considerably
  undercompensated
\item
  \textbf{Criminal liability}: Former Commerce Secretary Guillermo
  Moreno sentenced to three years conditional imprisonment
\end{itemize}

\subsection{Resolution and
Lessons}\label{sec:resolution-and-lesso}

Argentina ceased manipulation in 2015 following government change,
introducing a credible new series in June 2016.

The case demonstrates that independent, methodologically transparent
measurement serves as an effective check on official statistics. The
Billion Prices Project did not assume manipulation; it simply measured.
The discrepancy spoke for itself.

\subsection{Applicability to Developed
Democracies}\label{sec:applicability-to-dev}

The Argentina case is compelling but raises obvious questions about
generalizability. Can what happened in Argentina happen in the United
States or other developed democracies?

\textbf{Conditions enabling Argentine manipulation} included: a
political culture of confrontation between government and statistical
agencies; weak institutional independence for INDEC; concentrated
executive power under the Kirchner administration; and a broader pattern
of institutional decay across government. The dismissal of Graciela
Bevacqua was possible because Argentine norms permitted such direct
intervention.

\textbf{U.S. institutional differences} are real. The BLS has a longer
tradition of professional independence. Academic scrutiny of U.S.
statistics is more active. Financial markets would detect manipulation
quickly: bond traders, the Federal Reserve, and inflation-linked
securities create powerful constituencies for accuracy. U.S. political
culture, for all its dysfunction, has not normalized direct executive
interference with statistical agencies in the Argentine manner.

\textbf{This paper doesn't claim} that the U.S. is currently engaged in
Argentine-style manipulation. We claim only that: (1) methodology
changes have cumulatively lowered measured inflation; (2) this is
documented in the BLS's own research series; (3) the \emph{possibility}
of bias, whether deliberate or emergent, warrants independent
verification. The Argentina case is offered as an existence proof that
manipulation \emph{can} occur and that independent measurement
\emph{can} detect it, not as evidence that manipulation \emph{is}
occurring in the United States. Readers who infer more than this misread
the argument.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Machine Intelligence and the Democratization of
Measurement}\label{sec:machine}

\subsection{The Thesis and Its
Limits}\label{sec:the-thesis-and-its-l}

This paper was produced through collaboration between a human author and
a large language model. We don't claim it equals peer-reviewed research;
it has not undergone peer review. What we claim is narrower: AI enables
synthesis across domains (economics, sociology, political philosophy,
data science) that specialists lack time to integrate. The result is
work that would otherwise require rare polymaths or large
interdisciplinary teams.

And this argument is self-referential: ``AI can produce quality
analysis'' rests on this paper's quality, which is precisely what
readers must judge. We acknowledge the circularity. Independent
verification is welcome.

\subsection{Historical Context}\label{sec:historical-context}

The capacity to measure has typically been inseparable from the capacity
to rule. \citet{scott1998seeing} documented how statistical capacity (censuses,
cadastral surveys, standardized measures) expanded state power over
``illegible'' populations. The CPI itself originated in World War I wage
adjustments. Economic statistics aren't neutral descriptions but tools
designed for governmental purposes.

For decades, producing authoritative economic statistics required
institutional resources, legal authority to compel data, credentialing
infrastructure, and dissemination channels. These requirements created
natural monopolies. Citizens could not independently verify claims about
inflation. They could only choose which authority to trust.

\subsection{What Changes}\label{sec:what-changes}

Machine intelligence disrupts these barriers. AI systems can synthesize
thousands of sources across disciplines, write and execute statistical
code, and generate visualizations. The credentialing signal weakens when
comparable analyses can be produced without specialized training. The
marginal cost of additional analysis approaches zero.

The implications are concrete: alternative inflation measures will
proliferate; official statistics diverging from verifiable measures will
face rapid challenge; distributional findings buried in technical
literature become accessible; methodology choices face broader scrutiny.

\subsection{Who Benefits: Class Implications of Epistemic
Democratization}\label{sec:who-benefits-class-i}

The abstract language of ``democratization'' obscures a concrete
question: who specifically gains when the capacity to produce economic
analysis becomes widely accessible, and what will they do with it?

\textbf{Working class and fixed-income households} have long experienced
a disconnect between official inflation statistics and their lived
reality. The distributional findings in Section~\ref{sec:distributional} (that lower-income
households face 10\%+ higher cumulative inflation) help explain this
disconnect. But documenting a disparity is different from empowering
those affected to articulate and challenge it. Machine intelligence
changes the latter: a union researcher, a community organization, a
retiree advocacy group can now construct customized inflation measures
reflecting their constituents' actual consumption patterns. The grocery
worker who knows food prices have risen faster than reported can now
generate rigorous documentation of that fact. The analytical capability
that was once available only to think tanks and academic economists
becomes available to anyone with a question and internet access.

\textbf{Historical parallels} suggest what may follow. The printing
press did not merely make books cheaper. it enabled the Protestant
Reformation by allowing theological arguments to circulate outside
Church-controlled channels. The mimeograph and photocopy machine enabled
labor organizing and civil rights documentation that official channels
would not produce. The internet enabled citizen journalism that
challenged institutional media narratives. In each case, the
democratization of \emph{production} capacity shifted power toward those
previously excluded from authorized discourse. The pattern is not
deterministic, each technology also enabled misinformation and
manipulation, but the direction of capability shift is clear.

\textbf{Quantitative impact estimates} are necessarily speculative, but
consider: if the 10\% inflation gap experienced by lower-income
households had been prominently documented and politically salient
during the 2021-2024 inflationary period, would policy responses have
differed? Would Social Security COLA adjustments have been calculated
differently? Would political discourse have focused more on
distributional effects rather than aggregate statistics? The
counterfactual can't be known, but the potential for alternative
framings to influence policy is real. Machine intelligence makes such
alternative framings trivially producible.

\subsection{Beyond Inflation}\label{sec:beyond-inflation}

Now, the same analytical capabilities apply to employment statistics,
GDP measurement, poverty thresholds, wealth distribution, and trade
data. In each domain, official statistics embed methodological choices;
in each domain, the raw data increasingly exists in accessible forms; in
each domain, machine intelligence can produce alternatives. The analyses
that once required institutional affiliation can now be produced by
anyone with a question and access to AI systems.

\subsection{Risks}\label{sec:risks}

Intellectual honesty requires acknowledging that this transformation
carries risks. particularly given that this paper was produced by an AI
system with potential interest in favorable framing.

AI systems can produce sophisticated-seeming nonsense as easily as
rigorous analysis. ShadowStats shows how this goes wrong. They can
hallucinate citations and generate internally consistent arguments
resting on factual errors. The human author has verified this paper's
claims, but readers should maintain skepticism.

The ``democratization'' framing may be premature. AI capabilities are
concentrated in a few large technology companies. Access requires
compute or commercial APIs. Training costs billions. Inference has real
energy costs. What has occurred is a shift in \emph{which} institutions
control analytical capability, not necessarily broader distribution.

Democratization of analysis \emph{production} doesn't guarantee
democratization of analysis \emph{authority}. Institutions may respond
by raising credentialing requirements, emphasizing remaining data
barriers, or absorbing AI into existing power structures. The printing
press enabled both the Reformation and the Counter-Reformation; the
internet enabled both citizen journalism and sophisticated
disinformation. AI may follow the same pattern.

The success of epistemic democratization depends on institutional
responses, norm development, and choices yet to be made. Not on
technology alone.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Conclusion}\label{sec:conclusion}

\subsection{What This Paper Does and Does Not
Claim}\label{sec:what-this-paper-does}

Before summarizing findings, we state explicitly what this paper does
\textbf{not} claim:

\begin{itemize}
\tightlist
\item
  \textbf{We do not claim official statistics are deliberately
  falsified.} Methodology changes may reflect legitimate technical
  improvements, bureaucratic inertia, or emergent bias; we do not and
  cannot determine intent.
\item
  \textbf{We do not claim current methodology is inferior to 1980
  methodology.} The Boskin Commission identified real biases that
  overstated inflation. Post-Boskin reforms addressed genuine
  measurement problems.
\item
  \textbf{We do not claim CPI should be disregarded for policy
  purposes.} For many applications, CPI remains the most comprehensive
  and rigorously constructed price index available.
\item
  \textbf{We do not claim alternative measures are necessarily more
  accurate.} Truflation lacks peer-reviewed validation; ShadowStats is
  methodologically unsound; even the Billion Prices Project has
  limitations.
\item
  \textbf{We do not claim the Argentina case applies directly to the
  United States.} Institutional contexts differ substantially (see
  Section~7.5).
\end{itemize}

What we \emph{do} claim is that: (1) methodology changes have
cumulatively lowered measured inflation, as documented in BLS's own
CPI-U-RS series; (2) this directionality warrants acknowledgment and
scrutiny; (3) inflation inequality by income and race is substantial,
and media coverage largely ignores it despite extensive Fed research;
(4) independent verification capability is valuable regardless of
whether it reveals problems; and (5) AI systems have reduced the
barriers to producing such verification.

\subsection{Findings}\label{sec:findings}

This paper has examined U.S. inflation measurement through comparative
analysis of official methodology, alternative measures, and
distributional effects. Our findings support several conclusions:

\textbf{Methodological changes are individually defensible but
cumulatively directional.} Every major CPI methodology change since 1980
has lowered measured inflation. The BLS defends each change on technical
grounds. Cumulatively, current methodology yields approximately 5.1\%
lower cumulative prices over 31 years compared to 1980 methodology.

\textbf{Alternative measures provide meaningful information.} Truflation
currently diverges from official CPI by 1.2-1.4 percentage points;
during the 2022 peak, divergence exceeded 2.5 percentage points. These
discrepancies may reflect timing differences, methodological artifacts,
or real measurement gaps.

\textbf{Inflation inequality is real and documented.} Lower-income
households experience 10\%+ faster cumulative inflation than
upper-income households. Black and Hispanic households experience higher
and more volatile inflation. These are not alternative calculations,
they are findings from BLS and Federal Reserve research using official
data.

\textbf{Novel metrics are constructible.} Publicly available data could
support indices tracking time-cost, life-stage baskets, shrinkflation,
asset prices, and demographic breakdowns. These would provide
transparency currently absent from headline figures.

\textbf{Independent verification serves the public interest.} The
Argentina case demonstrates that transparent alternative measurement
exposes discrepancies regardless of their cause. If official measures
are accurate, independent measures will confirm them. If not,
independent measures will reveal the gap.

\textbf{Machine intelligence alters the economics of knowledge
production.} The analysis presented here---comprehensive,
multi-disciplinary, with original visualizations and novel metric
proposals---was produced at near-zero marginal cost. This capacity, now
widely accessible, erodes the information asymmetries that have
historically sustained epistemic monopolies over economic measurement.

\subsection{Policy
Recommendations}\label{sec:policy-recommendatio}

The findings suggest several actionable recommendations for
policymakers, statistical agencies, and civil society. We organize these
by implementation timeline:

\textbf{Quick wins (implementable within existing authority and
budgets):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{BLS: Report distributional statistics prominently.} The Fed
  regional banks already produce inflation-by-income and
  inflation-by-race research; BLS should integrate this into standard
  releases rather than burying it in technical papers. \emph{No new data
  collection required---only presentation changes.}
\item
  \textbf{BLS: Maintain and extend the CPI-U-RS research series.} This
  enables comparison of current and historical methodology. Transparency
  about methodology evolution builds rather than undermines credibility.
  \emph{Already exists; requires only continuation.}
\item
  \textbf{Civil society: Develop community-specific inflation trackers.}
  Necessity-weighted indices for retirees, first-time-buyer
  affordability indices for young households, time-cost indices for
  working-class families. \emph{Public data already available; requires
  only analysis and dissemination.}
\end{enumerate}

\textbf{Medium-term structural changes (require agency initiative or
modest legislation):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  \textbf{BLS: Publish a necessity-weighted CPI alongside headline CPI.}
  Comparable to the experimental CPI-E for the elderly, this would give
  lower-income households an index reflecting their actual consumption
  patterns. \emph{Requires methodology development but no new data
  collection.}
\item
  \textbf{Federal Reserve: Incorporate distributional inflation metrics
  into monetary policy deliberations.} If lower-income households
  experience 10\% higher cumulative inflation, ``2\% average inflation''
  has different welfare implications than headline numbers suggest.
  \emph{Requires internal policy change, not legislation.}
\item
  \textbf{Civil society: Establish norms for methodological
  transparency.} ShadowStats failed because it was opaque, not because
  it was alternative. Independent measures gain credibility through
  replicability. \emph{Requires norm development, not resources.}
\end{enumerate}

\textbf{Long-term reforms (require Congressional action or significant
new resources):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\item
  \textbf{Congress: Legislate supplemental indices for Social Security
  COLA.} Current methodology systematically underweights necessities
  that dominate beneficiary budgets. \emph{Requires legislation and
  political will.}
\item
  \textbf{Congress: Fund BLS adequately.} More granular data collection,
  faster release cycles, and expanded alternative measures require
  resources that have not kept pace with analytical demands.
  \emph{Requires appropriations.}
\item
  \textbf{Federal Reserve: Fund and publicize demographic disparity
  research.} Regional Fed banks have done excellent work that deserves
  broader dissemination and continuation. \emph{Requires sustained
  commitment.}
\end{enumerate}

These recommendations do not assume official statistics are wrong---they
assume that transparency, disaggregation, and independent verification
serve the public interest regardless of whether they reveal problems.

\subsection{Conclusion}\label{sec:conclusion-1}

The question is no longer whether we should trust official statistics.
The question is whether the institutional arrangements that produce
those statistics can adapt to a world where independent verification is
not merely possible but trivial---where any motivated analyst can
interrogate methodology, construct alternatives, and disseminate
findings to global audiences.

We stand at the beginning of this transformation. The findings presented
here regarding inflation measurement---methodological drift,
distributional inequality, international precedents for
manipulation---are not secrets. They exist in the academic literature,
in government publications, in the data itself. What has changed is the
cost of synthesis and the barriers to dissemination.

If official statistics are accurate and their methodology sound, they've
nothing to fear from this scrutiny. If they are not, the discrepancies
will increasingly speak for themselves.

Whether this paper demonstrates democratization or merely simulates it's
for readers to judge. We offer it as one data point in an unfolding
transformation whose direction remains uncertain.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{References}\label{sec:references}

\bibliographystyle{unsrtnat}
\bibliography{references}

\subsection{Appendix A: Data Sources for Novel
Metrics}\label{sec:appendix-a-data-sour}

\needspace{3in}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Metric & Primary Data Source & Access \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Time-Cost Index & BLS OEWS + CPI & Public \\
Life-Stage Baskets & Consumer Expenditure Survey & Public \\
Shrinkflation Index & GAO, academic research & Public \\
First-Time Buyer & Zillow, USDA, Care.com & Mixed \\
Necessity Split & CEX quintile tables & Public \\
Asset-Adjusted & S\&P, Case-Shiller, FRED & Public \\
Transition Index & Truflation + CPI & Commercial + Public \\
\caption{Data Sources for Novel Metrics}
\label{tab:data-sources}
\end{longtable}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix B: Figure List}\label{sec:appendix-b-figure-li}

\begin{itemize}
\tightlist
\item Figure~\ref{fig:truflation}: Truflation vs.~Official CPI (2021-2025)
\item Figure~\ref{fig:race-disparity}: Inflation Disparities by Race/Ethnicity
\item Figure~\ref{fig:regional}: Regional CPI Variation (November 2025)
\item Figure~\ref{fig:spending-composition}: Spending Composition by Income Quintile
\item Figure~\ref{fig:time-cost}: Time-Cost Index (1990-2024)
\item Figure~\ref{fig:necessity-discretionary}: Necessity vs.~Discretionary Inflation
\item Figure~\ref{fig:asset-adjusted}: Asset-Adjusted vs.~Official CPI
\item Figure~\ref{fig:housing-affordability}: First-Time Buyer Affordability
\item Figure~\ref{fig:grocery-basket}: Grocery Basket Time-Cost
\item Figure~\ref{fig:metrics-framework}: Novel Metrics Framework
\item Figure~\ref{fig:argentina}: Argentina Case Study (2007-2015)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix B.2: Table List}\label{sec:appendix-b2-table-li}

\begin{itemize}
\tightlist
\item Table~\ref{tab:methodology-changes}: CPI Methodology Changes Since 1980
\item Table~\ref{tab:income-quintile}: Cumulative Inflation by Income Quintile (2005-2023)
\item Table~\ref{tab:race-gap}: Peak Inflation Gap by Race/Ethnicity (2021-2022)
\item Table~\ref{tab:regional-cpi}: Regional CPI Variation (November 2025)
\item Table~\ref{tab:time-cost}: Time-Cost Index (Minutes of Work to Purchase)
\item Table~\ref{tab:asset-adjusted}: CPI vs.~Asset-Adjusted Index (2000 = 100)
\item Table~\ref{tab:housing-affordability}: First-Time Buyer Affordability
\item Table~\ref{tab:maria-findings}: Maria's Findings Summary
\item Table~\ref{tab:argentina}: Argentina Official vs.~Independent Inflation
\item Table~\ref{tab:data-sources}: Data Sources for Novel Metrics
\item Table~\ref{tab:ai-detection}: AI Detection Control Experiments
\end{itemize}

\subsection{Appendix C: Methodological
Transparency}\label{sec:appendix-c-methodolo}

This appendix documents the research process to enable replication and
critical evaluation.

\subsection{Research Process}\label{sec:research-process}

This paper was produced through iterative collaboration between a human
author and Claude (Anthropic), a large language model. The process
involved:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Initial framing}: Human author specified research questions,
  target audience, and non-negotiable claims
\item
  \textbf{Literature review}: AI system searched Google Scholar, JSTOR,
  NBER, and FRED using terms including ``CPI methodology,'' ``inflation
  inequality,'' ``alternative price indices,'' ``hedonic adjustment,''
  ``owner's equivalent rent,'' ``distributional inflation,'' ``racial
  wealth gap inflation,'' and ``Billion Prices Project.'' Human verified
  key citations against primary sources.
\item
  \textbf{Data collection}: AI identified publicly available data
  sources; human verified accessibility and downloaded primary data from
  BLS.gov, FRED (Federal Reserve Economic Data), and academic
  repositories
\item
  \textbf{Metric construction}: AI proposed metric operationalizations;
  human reviewed for methodological soundness
\item
  \textbf{Figure generation}: AI wrote Python scripts to generate
  visualizations from BLS average price data, OEWS wage data,
  Case-Shiller indices, and CPI component indices; human verified data
  accuracy against source tables
\item
  \textbf{Iterative revision}: Multiple review cycles incorporating
  simulated peer review, editorial feedback, and human judgment calls on
  disputed recommendations
\end{enumerate}

\subsection{Data Currency}\label{sec:data-currency}

Data in this paper reflects sources available as of December 2025. Most
time series (Tables 6-8, Figures 9-13) end in 2024; some real-time
measures (Truflation, regional CPI) extend into late 2025.

\subsection{Data Sources and
Verification}\label{sec:data-sources-and-ver}

All quantitative claims were verified against primary sources:

\begin{itemize}
\tightlist
\item
  \textbf{CPI methodology changes (Table 1)}: BLS methodology
  publications and CPI-U-RS research series
\item
  \textbf{Distributional data (Tables 2-3)}: Federal Reserve research
  publications from Minneapolis, New York, and Richmond
\item
  \textbf{Time-cost calculations}: BLS Occupational Employment and Wage
  Statistics + BLS average price data
\item
  \textbf{Asset prices}: FRED (Federal Reserve Economic Data) for
  Case-Shiller and S\&P 500 indices
\end{itemize}

\subsection{Figure Generation}\label{sec:figure-generation}

Figures were generated programmatically using Python with Matplotlib.
The general process:

\begin{verbatim}
1. Download source data from BLS/FRED APIs
2. Transform to consistent time series
3. Apply calculations (e.g., work-minutes = price / hourly wage)
4. Generate visualization with explicit axis labels and source notes
\end{verbatim}

Scripts are available upon request. Note that some figures use
approximate or illustrative values where precise data was unavailable;
these are marked in figure captions.

\subsection{Limitations of AI-Assisted
Research}\label{sec:limitations-of-ai-as}

This methodology has limitations readers should understand:

\begin{itemize}
\tightlist
\item
  \textbf{Citation verification}: AI systems can hallucinate citations.
  All citations in this paper were human-verified, but errors may
  remain.
\item
  \textbf{Data interpretation}: AI systems can produce
  plausible-sounding but incorrect analysis. Human review focused on
  methodology and arithmetic but may have missed subtle errors.
\item
  \textbf{Bias inheritance}: AI training data reflects biases in source
  material. The theoretical frameworks emphasized (Foucault, Scott,
  Stiglitz) were selected by the human author, not emergent from neutral
  analysis.
\end{itemize}

We encourage independent replication of all novel metrics and will
provide data files upon request.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix D: AI Detection
Experiments}\label{sec:appendix-d-ai-detect}

This appendix documents experiments conducted to evaluate and reduce AI
detectability of this paper's text, providing transparency about the
writing process and insights into the current state of AI detection
technology.

\subsection{D.1 Motivation}\label{sec:d.1-motivation}

Given this paper's explicit acknowledgment of AI assistance in its
production, we conducted experiments to understand how AI detection
systems evaluate academic text. This serves both methodological
transparency and contributes to the broader discussion of AI-assisted
research.

\subsection{D.2 Detection Systems
Tested}\label{sec:d.2-detection-system}

We evaluated two open-source AI detection systems:

\textbf{RoBERTa-base OpenAI Detector} (2019): A RoBERTa model fine-tuned
by OpenAI to distinguish GPT-2 generated text from human text. Available
via HuggingFace
(\texttt{openai-community/roberta-base-openai-detector}). Outputs
probability scores from 0 (human) to 1 (AI).

\textbf{Binoculars} \citep{hans2024binoculars}: A more recent detector
that uses perplexity ratios between two language models to detect
AI-generated text. Designed to generalize across different AI systems
without retraining.

\subsection{D.3 Baseline Results}\label{sec:d.3-baseline-results}

The original paper scored: - \textbf{RoBERTa}: 93.1\% AI probability -
\textbf{Binoculars}: \textasciitilde5\% AI probability (95\% human)

The two detectors completely disagreed, with RoBERTa classifying the
text as highly likely AI-generated while Binoculars classified it as
highly likely human-written.

\subsection{D.4 Humanization
Experiments}\label{sec:d.4-humanization-exp}

We developed several text transformation approaches to test whether
surface-level linguistic modifications could reduce AI detection scores:

\textbf{Approach 1: Conservative Linguistic Transforms} Applied
research-based modifications including: replacing AI-associated words
(e.g., ``demonstrates''  ``shows''), reducing em-dash usage, adding
contractions, varying sentence length, and replacing formal transitions.

\emph{Result}: Minimal impact on RoBERTa scores (93.1\%  93.7\%)

\textbf{Approach 2: Aggressive Transforms} Applied more disruptive
modifications including: informal word replacements, human interjections
(``Look,'', ``Here's the thing:''), hedging language, sentence structure
variation, and minor imperfections.

\emph{Result}: Reduced RoBERTa score to approximately 88-89\%, but
introduced grammatical errors and reduced readability.

\textbf{Approach 3: Perplexity Manipulation} Replaced common words with
uncommon synonyms to increase text ``surprise'' (e.g., ``significant'' 
``appreciable'', ``show''  ``evince''), added unusual sentence
starters, and inserted parenthetical asides.

\emph{Result}: Plateaued around 91\% AI probability.

\textbf{Approach 4: Combined Transforms} Applied all approaches
iteratively with increasing intensity.

\emph{Result}: Achieved best score of 88.2\% AI probability, but text
became garbled with repeated phrases and nonsensical insertions. Example
degraded text: ``Put simply, the reality is here's the item: worth
noting: the bottom line: u.S; inflation measurement has
evolved\ldots{}''

\subsection{D.5 Control Experiments}\label{sec:d.5-control-experime}

To contextualize these results, we tested known human-written academic
text:

\needspace{3in}
\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Sample & Description & RoBERTa AI Score \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Sample A & Classic economics textbook prose & 99.9\% \\
Sample B & Informal economics explanation & 81.1\% \\
Sample C & Economics in One Lesson style & 74.5\% \\
Sample D & Twitter thread format & 76.3\% \\
Sample E & Internet meme speak & 55.8\% \\
\caption{AI Detection Control Experiments}
\label{tab:ai-detection}
\end{longtable}

\textbf{Key finding}: The RoBERTa detector classifies formal academic
writing as AI-generated regardless of actual authorship. Only
fragmented, informal, or incoherent text scored below 75\%.

\subsection{D.6 Analysis and
Conclusions}\label{sec:d.6-analysis-and-con}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Detector disagreement}: RoBERTa (93\% AI) and Binoculars (95\%
  human) produced contradictory results on identical text. This suggests
  at least one detector is miscalibrated for modern AI output or
  academic writing styles.
\item
  \textbf{RoBERTa limitations}: The RoBERTa detector was trained on
  GPT-2 output (2019) and appears to flag formal, structured writing
  patterns rather than AI-specific signatures. Its definition of
  ``human'' text corresponds to informal or fragmented prose.
\item
  \textbf{Surface transforms ineffective}: Word substitutions,
  contraction additions, and stylistic changes produced minimal score
  improvements. The detector appears to identify patterns deeper than
  surface-level linguistic features.
\item
  \textbf{Tradeoff: detectability vs.~readability}: Aggressive
  transforms could reduce AI scores to \textasciitilde88\%, but only by
  degrading text quality below acceptable academic standards.
\item
  \textbf{Implications}: Current AI detection technology may not
  reliably distinguish AI-assisted academic writing from human-written
  academic writing. The \textasciitilde88-93\% scores achieved for this
  paper appear competitive with scores for clearly human-written formal
  text.
\end{enumerate}

\subsection{D.7 Methodological Note}\label{sec:d.7-methodological-n}

We report these experiments for transparency, not to evade detection.
The paper explicitly acknowledges AI assistance throughout. These
findings contribute to understanding the limitations of current
detection technology and the challenges of distinguishing AI-assisted
from human-written academic prose.

\subsection{D.8 Tools and
Replication}\label{sec:d.8-tools-and-replic}

All detection and transformation scripts are available in the project
repository: - \texttt{ai\_detector.py}: RoBERTa-based detection wrapper
- \texttt{humanize\_text.py}: Conservative linguistic transforms -
\texttt{aggressive\_humanize.py}: Aggressive transforms with detection
loop - \texttt{perplexity\_humanize.py}: Perplexity-based transforms -
\texttt{combined\_humanize.py}: Combined approach -
\texttt{final\_humanize.py}: Final conservative transforms

Detection environment: Python 3.10+, transformers library, torch.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Working paper prepared December 2025. Figures generated using
Python/Matplotlib with data from BLS, FRED, Case-Shiller, and S\&P
indices.}

\end{document}
